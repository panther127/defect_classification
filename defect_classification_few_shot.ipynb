{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpm2XymG7n6V",
        "outputId": "baf2b81b-5d08-42f2-f0b8-f701928ed6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset is stored in gdrive\n",
        "Data = '/content/gdrive/My Drive/MVTec_dataset/mvtec_anomaly_detection.tar.xz'"
      ],
      "metadata": {
        "id": "dubDN6wm72oS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import lzma\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import tarfile\n",
        "import contextlib\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import defaultdict\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CnNseKCM8YWR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since it is tar archive file --> using Lzma to extract this archive compressed file\n",
        "with contextlib.closing(lzma.LZMAFile(Data)) as xz:\n",
        "    with tarfile.open(fileobj=xz) as f:\n",
        "        f.extractall('./MVTec-AD')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "IXuTzySd74nD",
        "outputId": "a5ea4e68-5d57-4393-d210-20efce94d3f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-962d4e8075fd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# since it is tar archive file --> using Lzma to extract this archive compressed file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlzma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLZMAFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./MVTec-AD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def rename_images_with_folder_name(folder_path, folder_name):\n",
        "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
        "        raise ValueError(\"The provided path is not a valid directory.\")\n",
        "\n",
        "    image_extensions = (\".png\")\n",
        "\n",
        "    image_count = 0\n",
        "\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_ext = os.path.splitext(file_name)[1].lower()\n",
        "\n",
        "        if file_ext in image_extensions:\n",
        "            image_count += 1\n",
        "            new_file_name = f\"{folder_name}_{image_count:03d}{file_ext}\"\n",
        "            old_file_path = os.path.join(folder_path, file_name)\n",
        "            new_file_path = os.path.join(folder_path, new_file_name)\n",
        "            os.rename(old_file_path, new_file_path)\n"
      ],
      "metadata": {
        "id": "loYvni6QCkSB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(image_path, target_size=(256, 256)):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "    # If the image is not already in RGB mode, convert it to RGB\n",
        "    if img.mode != \"RGB\":\n",
        "        img = img.convert(\"RGB\")\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "NURcMnQYjmXe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(dataset_path, output_path, num_support_examples=5, num_query_examples=5):\n",
        "    # Create output directories\n",
        "    if not os.path.exists(output_path):\n",
        "      os.makedirs(output_path)\n",
        "    support_set_path = os.path.join(output_path, \"support_set\")\n",
        "    query_set_path = os.path.join(output_path, \"query_set\")\n",
        "    os.makedirs(support_set_path, exist_ok=True)\n",
        "    os.makedirs(query_set_path, exist_ok=True)\n",
        "\n",
        "    classes = os.listdir(dataset_path)\n",
        "    for class_name in classes:\n",
        "        if class_name == '.ipynb_checkpoints': continue\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "\n",
        "        print(class_path)\n",
        "        # Create class directories in support set and query set\n",
        "        support_class_dir = os.path.join(support_set_path, class_name)\n",
        "        query_class_dir = os.path.join(query_set_path, class_name)\n",
        "        os.makedirs(support_class_dir, exist_ok=True)\n",
        "        os.makedirs(query_class_dir, exist_ok=True)\n",
        "\n",
        "        # Get list of images in the 'good' folder (normal images) for this class\n",
        "        good_images_dir = os.path.join(class_path, \"train\", \"good\")\n",
        "\n",
        "        # rename images with it label\n",
        "        rename_images_with_folder_name(good_images_dir, class_name)\n",
        "\n",
        "        good_images = [os.path.join(good_images_dir, img) for img in os.listdir(good_images_dir) if img.endswith(\".png\")]\n",
        "\n",
        "        # Randomly select support and query examples\n",
        "        selected_support_examples = random.sample(good_images, num_support_examples)\n",
        "        selected_query_examples = random.sample(good_images, num_query_examples)\n",
        "\n",
        "        # Resize and move support examples to support set directory\n",
        "        for img_path in selected_support_examples:\n",
        "          img = resize_image(img_path)  # Resize the image\n",
        "          img.save(os.path.join(support_class_dir, os.path.basename(img_path)))\n",
        "\n",
        "\n",
        "\n",
        "        # Resize and move query examples (including defect images) to query set directory\n",
        "        query_defect_dir = os.path.join(class_path, \"test\")\n",
        "\n",
        "\n",
        "        for img_path in selected_query_examples:\n",
        "          img = resize_image(img_path)  # Resize the image\n",
        "          img.save(os.path.join(query_class_dir, os.path.basename(img_path)))\n",
        "\n",
        "\n",
        "        defect_folders = os.listdir(query_defect_dir)\n",
        "        for defect_folder in defect_folders:\n",
        "            defect_images_dir = os.path.join(query_defect_dir, defect_folder)\n",
        "            defect_folder = class_name if defect_folder == 'good' else defect_folder\n",
        "            # rename images with it label\n",
        "            rename_images_with_folder_name(defect_images_dir, defect_folder)\n",
        "            defect_images = [os.path.join(defect_images_dir, img) for img in os.listdir(defect_images_dir) if img.endswith(\".png\")]\n",
        "            for img_path in defect_images:\n",
        "                img = resize_image(img_path)  # Resize the image\n",
        "                img.save(os.path.join(query_class_dir, os.path.basename(img_path)))\n",
        "\n"
      ],
      "metadata": {
        "id": "GC4EQbtp8ToM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"./MVTec-AD/\"\n",
        "output_path = \"./MVTec-AD_preprocessed\"\n",
        "\n",
        "# Number of support examples per class\n",
        "num_support_examples = 5\n",
        "\n",
        "# Number of query examples per class\n",
        "num_query_examples = 5\n",
        "\n",
        "preprocess_dataset(dataset_path, output_path, num_support_examples, num_query_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riKulWME8jFO",
        "outputId": "b78bcafc-b09f-4397-c397-1e3ec3220b8b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./MVTec-AD/hazelnut\n",
            "./MVTec-AD/zipper\n",
            "./MVTec-AD/transistor\n",
            "./MVTec-AD/carpet\n",
            "./MVTec-AD/wood\n",
            "./MVTec-AD/leather\n",
            "./MVTec-AD/grid\n",
            "./MVTec-AD/bottle\n",
            "./MVTec-AD/toothbrush\n",
            "./MVTec-AD/metal_nut\n",
            "./MVTec-AD/pill\n",
            "./MVTec-AD/cable\n",
            "./MVTec-AD/tile\n",
            "./MVTec-AD/screw\n",
            "./MVTec-AD/capsule\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Source path in Colab\n",
        "source_folder_path = 'MVTec-AD_preprocessed'\n",
        "\n",
        "# Destination path in Google Drive\n",
        "destination_folder_path = '/content/gdrive/My Drive/'\n",
        "\n",
        "# Copy the data folder to Google Drive\n",
        "!cp -r \"$source_folder_path\" \"$destination_folder_path\"\n"
      ],
      "metadata": {
        "id": "8Hbzphs1vDw1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'folder_name' with the name of the folder you want to delete\n",
        "folder_name = \"MVTec-AD_preprocessed\"\n",
        "\n",
        "# Use shutil.rmtree() to delete the folder\n",
        "shutil.rmtree(folder_name)"
      ],
      "metadata": {
        "id": "EoNDzG1Is3jV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#neural network for image encoding\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class PrototypicalNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Flatten the input size for the first linear layer\n",
        "        flattened_input_size = input_size * 256\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(flattened_input_size, self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_size, self.hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input tensor for the first linear layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "        embeddings = self.encoder(x)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "# load images from subfolders\n",
        "class CustomImageFolder(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root))\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        self.images = self._load_images()\n",
        "\n",
        "    def _load_images(self):\n",
        "        images = []\n",
        "        for target_class in self.classes:\n",
        "            class_dir = os.path.join(self.root, target_class)\n",
        "            if not os.path.isdir(class_dir):\n",
        "                continue\n",
        "            for image_name in os.listdir(class_dir):\n",
        "                image_path = os.path.join(class_dir, image_name)\n",
        "                images.append((image_path, self.class_to_idx[target_class]))\n",
        "        return images\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path, target = self.images[index]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n"
      ],
      "metadata": {
        "id": "WA8hvO8CUf5F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support_set_path = '/content/gdrive/My Drive/support_set'\n",
        "query_set_path = '/content/gdrive/My Drive/query_set'"
      ],
      "metadata": {
        "id": "TIIbluva9bkv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "input_size = 256 * 256 * 3  # Replace with the actual size of your resized image data\n",
        "hidden_size = 256\n",
        "num_classes = 14  # Number of classes\n",
        "num_support_examples = 5  # Number of support examples per class\n",
        "num_query_examples = 5  # Number of query examples per class\n",
        "num_episodes = 5  # Number of episodes for training\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an instance of the Prototypical Network model\n",
        "model = PrototypicalNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Define the loss function (e.g., cross-entropy loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Example data loaders for the support set and query set\n",
        "support_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "query_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "support_set = CustomImageFolder(support_set_path, transform=support_transform)\n",
        "query_set = CustomImageFolder(query_set_path, transform=query_transform)\n",
        "\n",
        "support_loader = DataLoader(support_set, batch_size=num_support_examples, shuffle=True)\n",
        "query_loader = DataLoader(query_set, batch_size=num_query_examples, shuffle=True)\n",
        "\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for support_batch, support_labels in support_loader:\n",
        "        for query_batch, query_labels in query_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass: compute embeddings for support set and query set\n",
        "            support_embeddings = model(support_batch)\n",
        "            query_embeddings = model(query_batch)\n",
        "\n",
        "            # Calculate distances between class prototypes and query embeddings\n",
        "            distances = torch.cdist(support_embeddings, query_embeddings)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(-distances, query_labels)  # Use negative distances for cross-entropy loss\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    print(f\"Episode [{episode+1}/{num_episodes}]: Average Loss: {total_loss/len(support_loader)}\")\n",
        "\n",
        "# Save the trained model if needed\n",
        "torch.save(model.state_dict(), \"path/to/save/model.pth\")\n"
      ],
      "metadata": {
        "id": "iIzJS5T_VSJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZbaaYP4veWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}